{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111cae45",
   "metadata": {},
   "source": [
    "This notebook helps with plotting and interpretation of the global seismic wavefield generated by the original 1D AxiSEM software (https://github.com/geodynamics/axisem) and processed as .sac files as in write_record_section.ipynb. It also includes optional generation and plotting functions for TauP predicted phase arrival times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd321828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy import signal, fft\n",
    "from subprocess import run\n",
    "import re\n",
    "import pandas as pd\n",
    "import obspy\n",
    "import obspy.signal.freqattributes as freqatt\n",
    "from obspy.core.util.attribdict import AttribDict\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b67629",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up variables for this run ###\n",
    "# run name should correspond to the mesh name given to inparam_mesh/the directory name passed to movemesh.csh\n",
    "run_name = \"CadekEPSCBW2_deep\"\n",
    "\n",
    "# directory containing the AxiSEM SOLVER folder\n",
    "sim_dir = \"~/Documents/Synthetics\"\n",
    "\n",
    "# directory containing saved filtered seismic traces etc. from write_record_section\n",
    "# this notebook assumes seisimic traces are stored with path format\n",
    "# f\"{working_dir}/{run_name}/{s2plot}{component}{datatype}.sac\"\n",
    "working_dir = \"~/Documents/Enceladus\"\n",
    "\n",
    "# let python know where the TauP install is\n",
    "TauP_dir = \"~/Software/TauP-2.6.1\"\n",
    "\n",
    "# name of phase list for TauP simulation\n",
    "phase_list = f\"{working_dir}/phases.txt\"\n",
    "\n",
    "#create folder for the TauP travel times calculations\n",
    "output_dir = f\"{working_dir}/TravelTimes/{run_name}\"\n",
    "\n",
    "# name of receiver file used in the simulation\n",
    "station = \"recfile\"\n",
    "\n",
    "# which component to plot\n",
    "component = \"Z\"\n",
    "\n",
    "# datatype names compatible with write_record_section notebook\n",
    "datatype = \"filt_1_6\" # e.g. filt_1_6, raw\n",
    "\n",
    "# duration should equal the simulation length (s)\n",
    "duration = 400\n",
    "\n",
    "# set write = 1 to save output figure\n",
    "write = 0\n",
    "\n",
    "# extract delta from the recorded simulation data\n",
    "f = open(f'{sim_dir}/SOLVER/{run_name}/Data_Postprocessing/info_matlab.dat')\n",
    "lines = f.readlines()\n",
    "line = lines[2].replace(' ', '')\n",
    "delta = line.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read a 2-column file and return x and y which are lists of floats\n",
    "def Read_2Col(file_name):\n",
    "    print(file_name)\n",
    "    with open(file_name, 'r') as data:\n",
    "        x = []\n",
    "        y = []\n",
    "        for line in data:\n",
    "            p = line.split()\n",
    "            x.append(float(p[0]))\n",
    "            y.append(float(p[1]))\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return station information from the seismogram file chosen including network, latitude + longitude, elevation, and depth\n",
    "def Read_Station(file_name, station):\n",
    "        with open(file_name, 'r') as data:\n",
    "            net = []\n",
    "            lat = []\n",
    "            lon = []\n",
    "            elev = []\n",
    "            depth = []\n",
    "            for line in data:\n",
    "                #find the line with the station name in\n",
    "                if station in line:\n",
    "                    p = line.split()\n",
    "                    print(p)\n",
    "                    net = p[1]\n",
    "                    lat = p[2]\n",
    "                    lon = p[3]\n",
    "                    elev = p[4]\n",
    "                    depth = p[5]\n",
    "                    \n",
    "        return net, lat, lon, elev, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read station information from receivers.dat file type\n",
    "def Read_Receivers(file_name):\n",
    "    lat = {}\n",
    "    lon = {}\n",
    "    with open(file_name, 'r') as data:\n",
    "        data = data.readlines()\n",
    "        n = data[0]\n",
    "        for i in range(1, len(data)):\n",
    "            #linesplit\n",
    "            data[i] = data[i].replace('/n', '')\n",
    "            line = data[i].split()\n",
    "            lat[str(i).zfill(4)] = str(90 - float(line[0])) # i+1 used to avoid plotting the first and last stations at 0 and 180 degrees\n",
    "            lon[str(i).zfill(4)] = line[1]\n",
    "            \n",
    "    return lat, lon, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59cf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read source data from source file, returns depth, lat+lon as strings\n",
    "def Read_Source(file_name):\n",
    "        with open(file_name, 'r') as data:\n",
    "            lat = []\n",
    "            lon = []\n",
    "            dep = []\n",
    "            for line in data:\n",
    "                if 'SOURCE_DEPTH' in line:\n",
    "                    p = line.split()\n",
    "                    dep = p[1]\n",
    "                if 'SOURCE_LAT' in line:\n",
    "                    p = line.split()\n",
    "                    lat = p[1]\n",
    "                if 'SOURCE_LON' in line:\n",
    "                    p = line.split()\n",
    "                    lon = p[1]\n",
    "                    \n",
    "        return dep, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find dominant period and background model for this run - file name should be location of inparam_mesh, outputs dominant period as a float\n",
    "def Read_mesh(file_name):\n",
    "    with open(file_name, 'r') as data :\n",
    "        DPeriod = []\n",
    "        bg_model = []\n",
    "        ext_model = []\n",
    "        for line in data :\n",
    "            if 'DOMINANT_PERIOD' in line :\n",
    "                p = line.split()\n",
    "                DPeriod = float(p[1])\n",
    "            if 'BACKGROUND_MODEL' in line :\n",
    "                p = line.split()\n",
    "                bg_model = p[1]\n",
    "            #external model has a # at the start of the line if it's not in use; ext_model therefore = 'EXT_MODEL' when not in use\n",
    "            if  'EXT_MODEL' in line :\n",
    "                p = line.split()\n",
    "                ext_model = p[1]\n",
    "            \n",
    "    return DPeriod, bg_model, ext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb862158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read station data\n",
    "stalat, stalon, n = Read_Receivers(f\"{sim_dir}/SOLVER/{run_name}/receivers.dat\")\n",
    "\n",
    "# double check station spacing\n",
    "staspacing = abs(float(stalat[\"0001\"]) - float(stalat[\"0002\"]))\n",
    "print(staspacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dominant period and background model\n",
    "DPeriod, bg_model, ext_model = Read_mesh(f\"{sim_dir}/SOLVER/{run_name}/inparam_mesh\")\n",
    "print(DPeriod)\n",
    "\n",
    "#convert to TauP format input background model\n",
    "print(bg_model)\n",
    "print(ext_model)\n",
    "\n",
    "#if bg_model is set to external, converts straight to that file instead\n",
    "convert_models = {\n",
    "    \"prem_iso\": \"prem\",\n",
    "    \"iasp91\": \"iasp91\",\n",
    "    \"ak135\": \"ak135\",\n",
    "    \"ak135f\": \"ak135\",\n",
    "    \"external\": ext_model.split('.')[0]\n",
    "}\n",
    "\n",
    "taup_model = f\"{working_dir}/{convert_models[bg_model]}.nd\"\n",
    "print(taup_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e77b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read source data\n",
    "source_dep, evtlat, evtlon = Read_Source(f\"{sim_dir}/SOLVER/{run_name}/inparam_source\")\n",
    "\n",
    "#convert to strings for the TauP call\n",
    "source_dep = str(source_dep)\n",
    "evtlat = str(evtlat)\n",
    "evtlon = str(evtlon)\n",
    "print(evtlat)\n",
    "print(evtlon)\n",
    "print(taup_model)\n",
    "print(source_dep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-p flag means no error occurs if mkdir already exists and it doesn't have to do anything\n",
    "run(['mkdir', '-p', output_dir])\n",
    "\n",
    "# run TauP for chosen phase list in order to plot predicted arrival times and phase ids on the record section\n",
    "for station in stalat.keys():\n",
    "    output_path = f\"{output_dir}/{station}\"\n",
    "    run([f'{TauP_dir}/bin/taup_time', '-mod', taup_model, '-h', source_dep, '-pf', phase_list, '-sta', stalat[station], stalon[station], '-evt', evtlat, evtlon, '-o', output_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ba714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read ttimes calculations\n",
    "def Read_TTimes(file_name, DPeriod):\n",
    "    arrival = {}\n",
    "    k = 0\n",
    "    with open(file_name, 'r') as data:\n",
    "        for line in data:\n",
    "            #try here because the file's first few lines are headers; we only want the phase name and the arrival time\n",
    "            try :\n",
    "                p = line.split()\n",
    "                #if the first 'word' on the line is not a number, the exception is triggered\n",
    "                float(p[0])\n",
    "                phase = p[2]\n",
    "                phase2 = p[2]\n",
    "                # if this phase already exists in the arrival dictionary, we add a number on the end for multipathing\n",
    "                if phase in arrival.keys():\n",
    "                    arrivals_list = ' '.join(list(arrival.keys()))\n",
    "                    phase2 = phase + str(len(re.findall(f\"{phase}\\d\",arrivals_list))+1)\n",
    "                print(phase2)\n",
    "                #arrival dictionary containing phases as keys and arrival times as values\n",
    "                arrival[phase2] = float(p[3]) - (0.5*DPeriod)\n",
    "                if k == 0:\n",
    "                    distance = p[0]\n",
    "                    k = 1\n",
    "            except :    \n",
    "                pass\n",
    "    return arrival, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dac58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get and print the arrival dictionary, include DPeriod to remove 1/2 offset\n",
    "arrivals = {}\n",
    "distances = {}\n",
    "for station in stalat.keys():\n",
    "    output_path = f\"{output_dir}/{station}\"\n",
    "    print(station)\n",
    "    arrivals[station], distances[station] = Read_TTimes(f\"{output_path}.gmt\", DPeriod)\n",
    "    \n",
    "print(arrivals)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0ee3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set every nth sample to plot (reduces jupyter notebook memory requirements to speed up plotting)\n",
    "downsample = 5 \n",
    "\n",
    "# adjust the scale of the plot (will autoscale the amplitude bar)\n",
    "scale_factor = 100000000\n",
    "\n",
    "# choose whether to plot each trace starting at the same station time (0), or at the same TauP-predicted arrival time (1)\n",
    "phase_zero_plot = 0\n",
    "\n",
    "# if phase_zero_plot = 1, choose which TauP phase to zero on\n",
    "phase_zero = 'PcP'\n",
    "\n",
    "# choose whether to plot TauP predictions on the figure\n",
    "TauP_plot = 0\n",
    "\n",
    "st = obspy.read(f\"{working_dir}/{run_name}/00*{component}{datatype}.sac\", headonly=True)\n",
    "i = 0\n",
    "\n",
    "# begin plotting\n",
    "\n",
    "fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=run_name,x=0.01,y=0.8)))\n",
    "time = np.arange(0,duration+downsample*float(delta),downsample*float(delta))\n",
    "\n",
    "TauP_s2plots = []\n",
    "phase_lag = {}\n",
    "\n",
    "for tr in st:\n",
    "    i = i+1\n",
    "    if i > 1 and i < 25:\n",
    "        s2plot = tr.stats['station']\n",
    "        data = obspy.read(f\"{working_dir}/{run_name}/{s2plot}{component}{datatype}.sac\", headonly=False)[0]\n",
    "        data.decimate(downsample)\n",
    "        plotfiltdata = [float(x)*scale_factor + staspacing*(int(s2plot)-1) for x in data]\n",
    "        if phase_zero_plot == 1:\n",
    "            print(arrivals[s2plot].keys())\n",
    "            if phase_zero in arrivals[s2plot].keys():\n",
    "                print(s2plot)\n",
    "                # look up the TauP-predicted arrival time of chosen phase in the arrivals dict for this station\n",
    "                phase_zero_time = arrivals[s2plot][phase_zero]\n",
    "                phase_lag[s2plot] = phase_zero_time\n",
    "                fig.add_trace(go.Scatter(x=np.array(time-phase_zero_time), y=np.array(plotfiltdata),name=f\"{s2plot}\",line=dict(color='blue',width=0.65)))\n",
    "                TauP_s2plots.append(s2plot)\n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(x=np.array(time), y=np.array(plotfiltdata),name=f\"{s2plot}\",line=dict(color='blue',width=0.65)))\n",
    "            PFPFP = 0\n",
    "            TauP_s2plots.append(s2plot)\n",
    "            phase_lag[s2plot] = 0\n",
    "\n",
    "# create generic function to plot vertical lines such as for TauP arrivals and amplitude scaling\n",
    "line = np.linspace(-1*2, 2, 20)\n",
    "length = len(line)\n",
    "func = lambda length, arrival: [arrival]*length\n",
    "\n",
    "# add TauP arrival time predictions to plot\n",
    "if TauP_plot == 1:\n",
    "    for s2plot in TauP_s2plots:\n",
    "        for phase in arrivals[s2plot].keys():\n",
    "            plotline = [float(x) + float(distances[s2plot]) for x in line]\n",
    "            fig.add_trace(go.Scatter(x=func(length, arrivals[s2plot][phase]-phase_lag[s2plot]), y=plotline, name=f\"{phase}\",\n",
    "                                     line=dict(color='black', width=0.5)))\n",
    "            fig.add_trace(go.Scatter(x=[arrivals[s2plot][phase]-phase_lag[s2plot]], y=[plotline[0]],\n",
    "                                     mode=\"text\", text = [f\"{phase}\"]))\n",
    "\n",
    "# set y location of the amplitude scalebar\n",
    "amp_loc = 172.5\n",
    "\n",
    "# produce amplitude scalebar with automatic magnitude calculation\n",
    "plotline = [float(x)*2 + float(amp_loc) for x in line]\n",
    "plotend = [float(y)*0.7 + float(100) for y in line]\n",
    "\n",
    "fig.add_trace(go.Scatter(x=func(length,100),y=plotline,line=dict(color='crimson',width=0.8)))\n",
    "fig.add_trace(go.Scatter(x=plotend,y=func(length,amp_loc-4),line=dict(color='crimson',width=0.7)))\n",
    "fig.add_trace(go.Scatter(x=plotend,y=func(length,amp_loc+4),line=dict(color='crimson',width=0.7)))\n",
    "\n",
    "# 2*2 comes from the height of line being +/- 2 which is then multiplied by 2 in plotline\n",
    "scale_amplitude = int(2*2/scale_factor * 10**9)\n",
    "fig.add_trace(go.Scatter(x=[98],y=[amp_loc+0.5],mode=\"text\",text = [f\"Amplitude: \\u00B1 {int(scale_amplitude)} nm\"], textposition=\"top left\",textfont=dict(color='crimson')))\n",
    "\n",
    "fig.update_layout(width=1000, height = 500, showlegend=False, xaxis_title=\"Time (s)\", yaxis_title=\"Epicentral distance (deg)\", plot_bgcolor='rgba(0,0,0,0)')\n",
    "\n",
    "fig.update_xaxes(rangemode='tozero',range=[0,400],ticks=\"inside\", showline=True, linecolor='#444',title_font_color='#444')\n",
    "fig.update_yaxes(range=[0,180],ticks=\"inside\", dtick=15, showline=True, linecolor='#444',title_font_color='#444')\n",
    "fig.show()\n",
    "\n",
    "if write == 1:\n",
    "    fig.write_image(f\"{working_dir}/{run_name}/{run_name}_{component}_{datatype}_record_section.png\",scale=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851fe82",
   "metadata": {},
   "source": [
    "sS,pP,SKiKS,PcP,PKIKP,SKIKS,SKJKS,S,P,SS,PP,ScS,PKiKP,PKIIKP,PKJKP,PKikKiKP,PKikKikKiKP,pPKIKP,PKikKIKP,PKikKikKIKP,PcPPKIKP,PcPPKiKP,ScSSKiKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46aeb43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
