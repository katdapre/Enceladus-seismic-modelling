{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be2a45d",
   "metadata": {},
   "source": [
    "This notebook assists with processing raw output seismograms generated by the AxiSEM3D software (https://github.com/AxiSEMunity/AxiSEM3D). It assumes that you have followed the AxiSEM3D file structure; in cell 2 you can point the notebook to the relevant directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c542eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy import signal, fft\n",
    "from subprocess import run\n",
    "import re\n",
    "import pandas as pd\n",
    "import obspy\n",
    "import obspy.signal.freqattributes as freqatt\n",
    "from obspy.core.util.attribdict import AttribDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c29bcd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['mkdir', '-p', '/Users/kd16230/Documents/Enceladus/3D_modelling/LayeredCore_4Hz/simu1D/2DVQC400'], returncode=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### establish paths and variables ###\n",
    "# location of AxiSEM3D master directory\n",
    "axisem_loc = \"~/Documents/Synthetics/axisem3d_root/AxiSEM3D\"\n",
    "\n",
    "# this notebook assumes that the simulation input, output directories etc are located in \n",
    "# run_dir = f'{axisem_loc}/{model_name}/simu{run_dims}/{run_name}'\n",
    "# adjust file paths as necessary for your setup\n",
    "\n",
    "model_name = 'LayeredCore_4Hz'\n",
    "run_name = '2DVQC400'\n",
    "run_dims = '3D'\n",
    "\n",
    "run_dir = f'{axisem_loc}/{model_name}/simu{run_dims}/{run_name}'\n",
    "\n",
    "# master directory where processed seismic traces will be stored\n",
    "working_dir = \"~/Documents/Enceladus/3D\"\n",
    "\n",
    "# choose which station file (will affect output path)\n",
    "station_dims = '1D'\n",
    "station_dict = {'1D': 'stations.txt',\n",
    "               '3D': '3Dstations.txt'}\n",
    "\n",
    "# create directory to store processed seismic data\n",
    "output_dir = f'{working_dir}/{model_name}/simu{station_dims}/{run_name}'\n",
    "run(['mkdir', '-p', output_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f4872a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read event location\n",
    "run_dir = f'{axisem_loc}/{model_name}/simu{run_dims}/{run_name}'\n",
    "\n",
    "sta_lon = {}\n",
    "sta_lat = {}\n",
    "\n",
    "with open(f'{run_dir}/input/inparam.source.yaml', 'r') as file:\n",
    "    source_yaml = yaml.load(file, Loader=yaml.FullLoader)\n",
    "# request named source from the simulation e.g. SOUTH_POLAR_MRR, SOUTH_POLAR_NORMAL\n",
    "loc_leaf = source_yaml['list_of_sources'][0]['South_Polar_MRR']['location']\n",
    "event_latlon = loc_leaf['latitude_longitude']\n",
    "event_depth = loc_leaf['depth']\n",
    "\n",
    "# read list of stations\n",
    "with open(f'{run_dir}/input/{station_dict[station_dims]}','r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            p = line.split()\n",
    "            float(p[0])\n",
    "            sta_lat[str(p[0])]=p[2]\n",
    "            sta_lon[str(p[0])]=p[3]\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "431d87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.loadtxt(f'{run_dir}/output/stations/Enceladus_stations/data_time.ascii')\n",
    "\n",
    "#read 3-component data for every station\n",
    "disp = {'R':{},\n",
    "        'T':{},\n",
    "        'Z':{}}\n",
    "for station in sta_lat.keys():\n",
    "    for ich, ch in enumerate('RTZ'):\n",
    "        disp[ch][station] = np.array(np.loadtxt(f'{run_dir}/output/stations/Enceladus_stations/II.{station}.ascii')[:,ich])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "597bd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### construct filter ###\n",
    "\n",
    "sps = 1/float(time[1]-time[0]) # samples per second\n",
    "order = 4             # Order of the filter (corners)\n",
    "filter_type = 'bandpass'  # Filter type (e.g., 'highpass', 'lowpass', 'bandpass')\n",
    "band_cutoff = [3,4]       # Critical frequency or frequencies for filter in Hz (use [min_freq, max_freq] for 'bandpass')\n",
    "\n",
    "# Construct Butterworth filter\n",
    "sos = signal.butter(order, band_cutoff, btype=filter_type, fs=sps, output='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8596717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### process + write data ###\n",
    "\n",
    "# for each station:\n",
    "for station in sta_lat.keys():\n",
    "    s2write = station\n",
    "    \n",
    "    # for each component:\n",
    "    for component in disp.keys():\n",
    "        \n",
    "        # write processed unfiltered data\n",
    "        amp2 = obspy.Trace(data = disp[component][station].T)\n",
    "        amp2.detrend('simple')\n",
    "        amp2.detrend('demean')\n",
    "        amp2.taper(0.05,type='hann')\n",
    "        amp2.stats['sampling_rate'] = sps\n",
    "        amp2.stats['station'] = s2write\n",
    "        amp2.write(f'{output_dir}/{s2write}{component}raw.sac')\n",
    "\n",
    "        # write processed filtered data\n",
    "        f_data = signal.sosfiltfilt(sos, amp2, padtype='odd')\n",
    "        f_data2 = obspy.Trace(data = np.array(f_data))\n",
    "        f_data2.stats['sampling_rate'] = sps\n",
    "        f_data2.stats['station'] = s2write\n",
    "        f_data2.write(f\"{output_dir}/{s2write}{component}filt_{str(band_cutoff[0]).replace('.','')}_{str(band_cutoff[1]).replace('.','')}.sac\")\n",
    "        \n",
    "        # write processed unfiltered acceleration data\n",
    "        amp2.differentiate()\n",
    "        amp2.differentiate()\n",
    "        amp2.write(f\"{output_dir}/{s2write}{component}raw_acc.sac\")\n",
    "        \n",
    "        # write processed filtered acceleration data\n",
    "        f_data3 = signal.sosfiltfilt(sos,amp2,padtype='odd')\n",
    "        f_data4 = obspy.Trace(data = np.array(f_data3))\n",
    "        f_data4.stats['sampling_rate'] = sps\n",
    "        f_data4.stats['station'] = s2write\n",
    "        f_data4.write(f\"{output_dir}/{s2write}{component}filt_{str(band_cutoff[0]).replace('.','')}_{str(band_cutoff[1]).replace('.','')}_acc.sac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba31aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
